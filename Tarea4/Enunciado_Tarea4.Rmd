---
title: "Tarea 4"
output:
  html_document:
    df_print: paged
---

![](banner.png)

<center> <h1>Tarea 4: Bayesian Inference Part I</h1> </center>
<center><strong>CC6104: Statistical Thinking</strong></center>
#### **Integrantes :** 

- Tomas Alvarado
- Sebastian Brzovic

#### **Cuerpo Docente:**

-   Profesor: Felipe Bravo M.
-   Auxiliar: Ignacio Meza D.
-   Ayudantes: Gabriel Iturra, Stefano Schiappacasse, Sebastián Tinoco,
    María José Zambrano
            

#### **Fecha límite de entrega:**

### **Índice:**

1. [Objetivo](#id1)
2. [Instrucciones](#id2)
3. [Referencias](#id3)
2. [Primera Parte: Preguntas Teóricas](#id4)
3. [Segunda Parte: Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenid@s a la primera tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la primera parte del curso, los cuales se enfocan principalmente en introducirlos en la estadística bayesiana. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte teórica que busca evaluar conceptos vistos en clases. Seguido por una parte práctica con el fin de introducirlos a la programación en R enfocada en el análisis estadístico de datos. 

### **Instrucciones:**<a name="id2"></a>

- La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
- La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
- El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
- No serán revisadas tareas desarrolladas en Python.
- Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
- Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso. 


### **Referencias:**<a name="id3"></a>

Slides de las clases:

- [Introduction to Bayesian Inference](https://github.com/dccuchile/CC6104/blob/master/slides/3_1_ST-bayesian.pdf)
- [Summarizing the Posterior](https://github.com/dccuchile/CC6104/blob/master/slides/3_2_ST-posterior.pdf)


Videos de las clases:

- Introduction to Bayesian Inference: [video1](https://youtu.be/Gf2uuElPH0g) [video2](https://youtu.be/5ZZ3PTPdZQw) [video3](https://youtu.be/d_jXwM_-5jc) [video4](https://youtu.be/yZW1V3X4J94) [video5](https://youtu.be/-fw0ktR7psM) [video6](https://youtu.be/0oK9M82sw8Q) [video7](https://youtu.be/u7Qdw5rDDDU)
- Summarizing the Posterior: [video1](https://youtu.be/67o8wcZsgtk)  [video2](https://youtu.be/Xr8S1Uv_5GQ) [video3](https://youtu.be/XJKyW4tYp_0) [video4](https://youtu.be/OMipgV727wo)

Documentación:

- [rethinking](https://github.com/rmcelreath/rethinking)
- [tidyr](https://tidyr.tidyverse.org)
- [purrr](https://purrr.tidyverse.org)
- [dplyr](https://dplyr.tidyverse.org)
- [ggplot2](https://ggplot2.tidyverse.org/)

# Primera Parte: Preguntas Teóricas<a name="id4"></a>
A continuación, se presentaran diferentes preguntas que abordan las temáticas vistas en clases. Por favor responda cada una de estas preguntas de forma breve, no más de 4 o 5 lineas.

#### **Pregunta 1:**

Explique cual es la diferencia fundamental entre la estadística bayesiana y frecuentista.

> Tenemos por definicion que ambas estadisticas son diferentes, la frecuentista esta basada en que de acuerdo a los datos estos se pueden usar para calcular la probabilidad de que ocurra algo, basandose en la frecuencia con la que ocurre en una población. Por otro lado la bayesiana dicta que podemor ir actualizando el calculo de la probabilidad de que ocurra ese evento, ademas que ya que esta basada en el teorema de bayes e ir teniendo nuevos datos es como se van actualizando estas probabilidades, con lo cual se puede calcular la probabilidad de cualquier hipotesis.

#### **Pregunta 2:**

Discuta la siguiente afirmación **La inferencia bayesiana permite fácilmente utilizar distintos tipos de información**.

> Como vimos en la pregunta 1, la inferencia bayesiana ocupa el teorema de Bayes, con el cual al ir disponiendo de mas datos, esta probabilidad se iría actualizando, además de no estar cerrado a un solo tipo de dato y finalmente haciendo mucho más preciso el calculo de la probabilidad.

#### **Pregunta 3:**

Explique la diferencia entre **prior probability** y **posterior probability**

> La probabilidad previa es la probabilidad de que suceda el evento en cuestión sin antes tomar en cuenta los datos, por lo que es una medida de referencia. Por otro lado, la probabilidad posterior es la probabilidad de que suceda el evento pero teniendo todos los datos en cuenta. Ademas podemos notar que ambas probabilidades se pueden ir actualizando(como hablamos en las preguntas anteriores), y por ejemplo, con lo que en una nueva iteración podriamos tener que nuestra posterior será nuestra nueva previa y la nueva posterior será la calculada con los nuevos datos ingresados.

#### **Pregunta 4:**

El estadista bayesiano "Bruno Finetti" menciona la siguiente frase en su libro de probabilidad:  **La probabilidad no existe**. Lo que en verdad quizo decir es que la probabilidad es un método para describir incertidumbre en un observador con conocimiento limitado. Discuta esta información utilizando el ejemplo del lanzamiento del globo terraqueo visto en clases. ¿Que significa decir "la probabilidad de que sea agua es 0.7"?

> Basándonos en la frase del enunciado podemos inferir que la probabilidad es una medida para medir nuestro grado de incertidumbre y sino no conocemos todas las condiciones, no podemos decir con seguridad que algo es certero hasta lograr eso. Ahora, la frase “la probabilidad de que sea agua es 0.7” quiere decir que de acuerdo a la información que se tiene de la situación, sin conocer a plenitud esta, hay una probabilidad de 0.7 de que la sección elegida sea agua.


#### **Pregunta 5:**
¿ Que ventaja entrega que la distribución de la posterior este en la misma familia de distribución de probabilidad que la del prior?. De un ejemplo de alguna distribución que posee este comportamiento.

> Sabemos por todo lo anterior, que la gran ventaja de que ambas pertenezcan a la misma familia es que se puede calcular la posterior de manera sencilla de acuerdo a la previa y todos los datos actuales. Un ejemplo de una distribución con este comportamiento es la distribución normal.


#### **Pregunta 6:**
Señale y explique los pasos de la *grid approximation* para obtener la posterior y responda las siguientes preguntas:

a. ¿Cual de los pasos señalados nos permite obtener una distribución de la posterior mas precisa?.
b. Cuales son las limitaciones de la *grid approximation*.

> Los pasos para hacer el grid approximation son:
a)
- definir el grid con la cantidad de puntos
- grid tendra a su disposición una lista de valores que puede tomar cada uno de los parametros.
- Para los parametros se saca el valor de la previa
- Se repite este ultimo pero con el likelihood
- Se calcula la posterior, multiplicando likelihood con previa

> El paso mas importante para tener un calculo más preciso es el de calcular la previa, ya que a medida que esta se calcula con más datos, tendrá una mejor distribución y por ende al calcular el posterior será más certero.
b) Basicamente, si tenemos una gran cantidad de información, sucede que a la hora de tener que hacer los calculos, estos no son eficientes, por lo cual termina por resultar en que no es viable en el tiempo.


#### **Pregunta 7:**

¿ Por qué es necesario aprender a trabajar con muestras de la posterior?.

> Aprender a trabajar con la posterior es sumamente útil, ya que nos permite hacer aproximaciones, calcular media y varianza, y lo más útil de todo, que es lo que ya hemos visto en las preguntas anteriores, que uno puede ir ocupando la posterior actual en la siguiente “iteración”, siendo esta la previa, con lo cual al tener más datos y nueva información, se volverá más preciso el calculo de la probabilidad, permitiendonos sacar mejores conclusiones.


#### **Pregunta 8:**
Señale si las siguientes afirmaciones son verdaderas o falsas, en el caso que sean falsas justifique su respuesta:

- [F] Los point estimates de la posterior no entregan información relevante en un estudio. 

- [V] Un intervalo de confianza  es un intervalo dentro del cual un valor de parámetro no observado cae con una probabilidad particular, mientras que un intervalo de credibilidad es un rango de valores en el que se estima que estará cierto valor desconocido.

- [V] La principal ventaja de HPDI frente a un intervalo de credibilidad es que si la posterior no distribuye de forma normal, el HPDI será capaz de detectar los puntos de interés, mientras que un intervalo de credibilidad lo ignoraría al asumir simetría.

>  - Falso, ya que esta si es util en un estudio, ya que esta ocupa la informacion previa para saber lo que se necesita sobre una proposicion incierta, ya que se tiene conocimiento previo y un modelo matematico que lo describe, aparte a medida que se obtiene nueva informacion, esta se va actualizando.


#### **Pregunta 9** 

Suponga que tiene dos especies de pandas. Cada una de las especies es igual de común y es imposible distinguirlas físicamente. Una de las diferencias entre las especies es el tamaño de sus familias. Si denotamos por $\theta$ a la especie del panda se tiene que, cuando la especie es $\theta = 1$ tiene dos bebes un $10\%$ de las veces mientras que la especie $\theta = 2$ tiene dos bebes un $20\%$ de las veces, mientras que el resto de veces ambas especies tienen un solo bebe.

Suponga que usted esta intentando determinar la especie de un panda que que tiene como registro de nacimientos al conjunto $D$, considere quela especie de un panda que acaba de dar a luz a dos bebes, es decir $D = \{\text{dos bebes}\}$

- [ ] ¿Cual es la probabilidad de que pertenezca a la especie $1$?
- [ ] Suponga ahora que el mismo panda acaba de dar a luz y esta vez es solo un bebe. Calcule la probabilidad posterior de que el panda sea de especie $1$. ¿Que cambia con el calculo anterior?
- [ ] Suponga que le ofrecen hacer un test genético a su panda, como suele ser común con los test no es perfecto y le mencionan las siguientes características:

  - La probabilidad de que correctamente idenfitique a la especie $1$ es de $0.8$
  - La probabilidad de que correctamente identifique a la especie $2$ es de $0.65$

Se administra el test y se obtiene un resultado positivo a la especie $1$. Sin utilizar la información en $D$ calcule la probabilidad posterior de que su panda sea de la especie $1$. Repita sus cálculos utilizando la información recopilada en $D$. ¿En que varían sus resultados?


>a)  P(\theta = 1| D = 2) = \frac{P(D=2 | \theta = 1)P(\theta =1)}{P(D=2)} = \frac{0.1*0.5}{0.1*0.5 + 0.2*0.5}= \frac{1}{3}=0.333 

Dado la respuesta anterior, calculamos la posterior usando prior y likelihood.
Likelihood = P(D=1|\theta = 1) = \frac{9}{10}
Posterior = \frac{1}{3} *\frac{9}{10} = 0.3
De lo anterior podemos concluir que dado que nuestro likelihood es grande, entonces nuestra nueva probabilidad de que pertenezca a la especie 1 baja a 0.3.


---

# Segunda Parte: Elaboración de Código<a name="id5"></a>
En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

Para el desarrollo preste mucha atención en los enunciados, ya que se le solicitará la implementación de métodos sin uso de funciones predefinidas. Por otro lado, Las librerías permitidas para desarrollar de la tarea 4 son las siguientes:

```{r, eval=FALSE}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)

# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)

# Manipulación de varios plots en una imagen.
library(gridExtra)

# Análisis bayesiano
library(rethinking)
```

Si no tiene instalada la librería “rethinking”, ejecute las siguientes líneas de código para instalar la librería:

```{r, eval=FALSE}
install.packages("rethinking")
```

En caso de tener problemas al momento de instalar la librería con el código anterior, utilice las siguiente chunk:

```{r, eval=FALSE}
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
```

### Preguntas: Introducción a Grid Approximation
Las primeras dos preguntas de esta tarea tienen como objetivo introducirlos en la inferencia Bayesiana utilizando la técnica Grid Approximation para obtener una aproximación de la posterior. Al finalizar los problemas ustedes deberán ser capaces de visualizar los efectos que tiene el prior en la posterior, saber cómo realizar una Grid Approximation y comprender como utilizar Percentile Interval (PI) en una posterior.

### Pregunta 1:

Considere el dataset "moneda.csv" donde se encuentran los resultados de un experimento lanzando una moneda, el objetivo de esta pregunta es estudiar mediante técnicas de inferencia Bayesiana el valor de la probabilidad de que salga cara, representado por el valor $1$. Puede usar la librerira rethinking durante toda esta pregunta (si lo desea).

```{r}
# Análisis bayesiano
library(rethinking)

dataMoneda <- read.csv("moneda.csv", header = TRUE)
graficos_grid <- function(num_tiros){
  p_grid <- seq(from=0, to=1, length.out=num_tiros)
  lanzamientos <- dataMoneda[2:11,]
  prior <- rep(1,num_tiros)
  #e <- sum(p_grid)
  e <- sum(lanzamientos)
  likelihood <- dbinom(e, size = 10, prob = p_grid)
  unstd.posterior <- likelihood*prior
  posterior <- unstd.posterior/sum(unstd.posterior)
  plot(p_grid, posterior, type ="b", xlab="Probability", ylab="posterior probability")
  mtext=("Nro de tiros")
    
}

graficos_grid(10)
graficos_grid(50)
graficos_grid(100)
graficos_grid(250)
graficos_grid(500)
graficos_grid(998)
#Analizando los graficos vemos como se achicala curva mostrando que cada vez tiende mas a la probabilidad real de que de cara
dataMoneda <- read.csv("moneda.csv", header = TRUE)

graph_lap <- function(num_tiros){
  
  lanzamientos <- dataMoneda[2:(num_tiros + 1),]
  w <- sum(lanzamientos)
  l <- num_tiros - w
  globe.qa <- quap(
    alist(
      W ~ dbinom(W+L, p),
      p ~ dunif(0,1)
    ),
    data=list(W=w, L=l))
  precis(globe.qa)
  sample.quap <- extract.samples(globe.qa)
  dens(sample.quap)
}

graph_lap(5)
graph_lap(10)
graph_lap(50)
graph_lap(100)
graph_lap(250)
graph_lap(500)
graph_lap(999)
#Mientras mas datos tengo mas se acerca a la posterior
num_tiros <- 500
p_grid <- seq(from=0, to=1, length.out=num_tiros)
lanzamientos <- dataMoneda[2:11,]
prior <- rep(1,num_tiros)
e <- sum(lanzamientos)
likelihood <- dbinom(e, size = 10, prob = p_grid)
unstd.posterior <- likelihood*prior
posterior <- unstd.posterior/sum(unstd.posterior)

plot(posterior~p_grid)

samples <- sample(p_grid, prob = posterior, size = 1e5, replace = TRUE)
dens(samples)

sum1 <- sum(posterior[p_grid<0.4])
sum2 <- sum(posterior[0.4<p_grid & p_grid<0.7])
sum3 <- sum(posterior[p_grid>0.7])
sum1
sum2
sum3
#Los resultados muestran el porcentaje de la probabilidad posterior que esta entre los valores y mencionados y podemos ver claramente que la probabilidad de que p este entre 0 y 0.4 es mayor a los otros 2 por lo que podriamos decir que en base a los primeros 10 lanzamientos la moneda esta cargada, cosa que cambia cuando se aumenta cuando se obtiene mas informacion 
num_tiros <- 500
p_grid <- seq(from=0, to=1, length.out=num_tiros)
lanzamientos <- dataMoneda[2:501,]
prior <- rep(1,num_tiros)
e <- sum(lanzamientos)
likelihood <- dbinom(e, size = 500, prob = p_grid)
unstd.posterior <- likelihood*prior
posterior <- unstd.posterior/sum(unstd.posterior)

plot(posterior~p_grid)

samples <- sample(p_grid, prob = posterior, size = 1e5, replace = TRUE)
dens(samples)

sum1 <- sum(posterior[p_grid<0.4])
sum2 <- sum(posterior[0.4<p_grid & p_grid<0.7])
sum3 <- sum(posterior[p_grid>0.7])
sum1
sum2
sum3
num_tiros <- 500
p_grid <- seq(from=0, to=1, length.out=num_tiros)
lanzamientos <- dataMoneda[2:11,]
prior <- rep(1,num_tiros)
e <- sum(lanzamientos)
likelihood <- dbinom(e, size = 10, prob = p_grid)
unstd.posterior <- likelihood*prior
posterior <- unstd.posterior/sum(unstd.posterior)

plot(posterior~p_grid)

samples <- sample(p_grid, prob = posterior, size = 1e5, replace = TRUE)
#dens(samples)

sum1 <- sum(posterior[p_grid<0.4])
sum2 <- sum(posterior[0.4<p_grid & p_grid<0.7])
sum3 <- sum(posterior[p_grid>0.7])

PI(samples, prob=0.5)
PI(samples, prob=0.75)
PI(samples, prob=0.95)


HPDI(samples, prob=0.5)
HPDI(samples, prob=0.75)
HPDI(samples, prob=0.95) #siempre va a contener el valor maximo

```


- [ ] Programe el metodo grid approximation para distintos tamaños de experimento. ¿Como van cambiando las curvas posterior?
- [ ] Repita el mismo análisis anterior pero utilizando el método de Laplace (no necesita programar el método, puede utilizar la libreria "rethinking"). ¿Como se comparan con los resultados anteriores?.
- [ ] Grafique la densidad de la posterior y encuentre la proporción de los siguientes defined boundaries:

  - [ ] $(0, 0.4)$
  - [ ] $(0.4,0.7)$
  - [ ] $(0.7,1)$

¿Como puede interpretar los resultados? 

- [ ] Calcule un intervalo de credibilidad al $50\%$, $75\%$ y $95\%$. ¿Como se puede interpretar los resultados? ¿Cual podría ser un problema al usar intervalos de credibilidad?.
- [ ] Genere los intervalos HDPI para $50\%$, $75\%$ y $95\%$, compárelos con  los intervalos de credibilidad de la parte anterior. ¿En que se diferencian los intervalos de credibilidad con los HDPI?.

> Respuesta Aqui

---

### Pregunta 2: Grid Approximation y Sample prediction

El objetivo de esta pregunta es comprender el concepto de `sample prediction` visto en clases y realizar predicciones en base a una posterior. 

Un conjunto de carteros aburridos de las mordidas de perros ha decidido realizar un catastro de mordidas recibidas por los empleados de su empresa en un periodo de dos meses, planeando en base a estos datos realizar inferencia bayesiana. Los datos de las mordidas estas datos por el dataset `no+mordidas.csv`, en donde cada fila representa las mordidas recibidas por diferentes carteros y las columnas señalan si fue mordido o no el cartero en los meses de estudio (notar que si fue mordido sera señalado con un 1, de lo contrario es señalado con un 0). Cabe señalar que un cartero no puede ser mordido mas de una vez al mes, ya que el damnificado recibe licencia por todos los días restantes del mes tras la mordida, reincorporándose el siguiente mes al trabajo.

```{r}
df = read.csv("no+mordidas.csv")
head(df)

Vict <- sum(df$bites_month_1) + sum(df$bites_month_2)
defe <- sum(df$bites_month_1 == 0) + sum(df$bites_month_2==0)
p_grid<-seq(from=0, to=1, length=500)
prior<-rep(1, 500)
likelihood<-dbinom(Vict, size=Vict+defe, prob = p_grid)
unstd.posterior <- likelihood*prior
posterior <- unstd.posterior/sum(unstd.posterior)
maximo<-max(posterior)
maximo

repl<- rbinom(10000, 500, prob = maximo)
hist(repl)
real_bite_count<-NULL
for(i in 1:length(df$bites_month_1)){
  real_bite_count<-append(real_bite_count,df$bites_month_1[i]+df$bites_month_2[i])
}
hist(real_bite_count)

#Analizando los dos histogramas, notamos que se aleja un poco de los datos reales mostrando una sobre representacion de los carteros que no fueron mordidos en el periodo de 2 meses. Esto se puede entender talvez por pocas opciones (0, 1, 2 mordidas)


df = read.csv("no+mordidas.csv")
head(df)
df1 <- df[df$bites_month_1==1,]
df1

Vict <- sum(df1$bites_month_2)
defe <- sum(df1$bites_month_2==0)
p_grid<-seq(from=0, to=1, length=500)
prior<-rep(1, 500)
likelihood<-dbinom(Vict, size=Vict+defe, prob = p_grid)
unstd.posterior <- likelihood*prior
posterior <- unstd.posterior/sum(unstd.posterior)
maximo<-max(posterior)
maximo

repl<- rbinom(10000, 500, prob = maximo)
hist(repl)
real_bite_count_2<-NULL
for(i in 1:length(df$bites_month_1)){
  real_bite_count_2<-append(real_bite_count_2,df1$bites_month_2[i])
}
hist(real_bite_count_2)

#Tomando los datos de los que ya fueron mordidos vemos que los graficos se parecen pero no de la manera esperada puesto que la proporcion entre los mordidos por 2da vez y no, no fue la misma. Pensamos que este error se debe a lo mismo la pregunta anterior
```

En base a los datos, realice los siguientes puntos:

- [ ] Realice una *grid approximation* para estimar la probabilidad que un cartero sea mordido, para esto junte los datos del mes 1 y 2 de estudio. Señale el máximo valor de la posterior.

- [ ] Utilizando la posterior obtenida en el paso anterior, utilice rbinom para simular 10.000 réplicas de 500 registros de mordidas. Con esto, deberá obtener 10.000 números, cada uno de los cuales es un recuento de las mordidas obtenidas en el registro de datos. Compare la distribución del número de los carteros mordidos predichos con el número real de los datos (248 carteros mordidos de un total de 500 datos). ¿El modelo se ajusta bien a los datos? Es decir, ¿la distribución de las predicciones incluye la observación real como resultado central y probable?

- [ ] Como se comento en el comienzo `bites_month1` contiene las mordidas señaladas por un conjunto de personas en el primer mes. Haciendo uso de `bites_month2`, obtenga la posterior de que una persona que fue mordida en el primer mes, sea mordida nuevamente en el segundo mes. Para esto, se recomienda comenzar buscando los carteros que fueron mordidos el primer mes y en base a estos generar una búsqueda indexada para obtener el número solicitado. Hecho esto, simule ese número carteros mordidos 10.000 veces. De los resultados obtenidos, compare el recuento de carteros mordidos con el recuento real. ¿Cómo se ve el modelo desde este punto de vista?

> 

---

### Pregunta 3:

En esta pregunta se trabajara con el dataset "notas.csv" el cual contiene las notas históricas de un curso desconocido. Suponga que los datos vienen de una distribución $\mathcal{N}(\mu,\sigma^2)$, el objetivo de la pregunta es estudiar el comportamiento de los datos y los posibles valores de $\mu,\sigma$ mediante técnicas de inferencia Bayesiana.

Usted sabe un dato extra sobre la información, los valores de $\sigma$ en la grilla se mueven en el intervalo $[0.5,1.5]$ y, además, tiene una fuerte creencia a que es mas probable encontrar la desviación estándar real entre $[0.5,1]$ que en $(1,1.5]$. De hecho, estudios señalan que la probabilidad de encontrar sigma en los valores $[0.5,1]$ es de 2/3, mientras que 1/3 para el resto de intervalos.


- [ ] Modifique el siguiente código que permite realizar una grid approximation para $2$ parámetros. Proponga priors para $\mu$ y $\sigma$, justifique su elección.


```{r, eval=FALSE}
# Leer información
data_notas <- read.csv("notas.csv")

# Función para crear likelihood dado mu y sigma
grid_function <- function(mu,sigma){ 
   dnorm(data_notas$Notas, mu, sigma)
}
num_points = 102
# Valores de la grilla
grid_mu <- seq(from=1, to=7, length.out=num_points)
grid_sigma <- seq(from=0.5, to=1.5, length.out=num_points)

# Se crea la grilla 2d
data_grid <- expand_grid(grid_mu,grid_sigma)

# Se guarda la likelihod
data_grid$likelihood <- map2(data_grid$grid_mu,data_grid$grid_sigma, grid_function)

# Se transforma el forma de map2 a una columna
data_grid <- unnest(data_grid,cols = c("likelihood"))


# Valores de los priors
prior_mu <- rep(1, num_points)
prior_sigma <- c(rep(2/3,num_points/2), rep(1/3,num_points/2))

# Se crea la grilla 2d de priors
prior <- expand_grid(prior_mu,prior_sigma)

# Se calculan los valores del prior
data_grid$prior <-  map2(prior$prior_mu,prior$prior_sigma, prod)
data_grid <- unnest(data_grid,cols = c("prior"))

# Se calcula el posterior
data_grid$unstd_posterior <-  data_grid$likelihood * data_grid$prior

# Se estandariza el posterior
data_grid$posterior <- data_grid$unstd_posterior/sum(data_grid$unstd_posterior)

# Se ajustan los valores de la posterior para que no sean valores tan pequñeos
data_grid$posterior <- (data_grid$posterior - min(data_grid$posterior))/(max(data_grid$posterior)-min(data_grid$posterior))

```

- [ ] Tras haber ejecutado el código de la parte anterior ejecute el siguiente, ¿Que puede decir de los valores de la distribución? Se recomienda hacer modificaciones en el código para realizar un mejor análisis y estudio.


```{r, eval=FALSE}
# Punto de referencia
# Se recomienda cambiar estos valores por unos adecuados que le permitan estudiar
# Los valores de la distribución de mejor manera
valor_x <- 1
valor_y <- 1

# Grafico

punto_comparacion <- tibble(x = valor_x, y = valor_y)

plt <- data_grid %>%
  ggplot(aes(x = grid_mu, y = grid_sigma)) +
  geom_raster(aes(fill = posterior),
    interpolate = T
  )+ 
  geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
  geom_label(
    data = punto_comparacion, aes(x, y),
    label = "Punto Comparación",
    fill = "green",
    color = "black",
    nudge_y = 0, # Este parametro desplaza la caja por el eje y
    nudge_x = 1 # Este parametro desplaza la caja por el eje x
  )+
  scale_fill_viridis_c() +
  labs(
    title = "Posterior para Mean y Standard Deviation",
    x = expression(mu ["Mean"]),
    y = expression(sigma ["Standar Deviation"])
  ) +
  theme(panel.grid = element_blank())

plt
```

- [ ] A continuación se presenta un código que permite realizara la distribución dada por sampling from grid approximation ¿Para que sirve este proceso? ¿Que puede deducir del gráfico?


```{r}
# Codificamos los datos
x <- 1:length(data_grid$posterior)

# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)

# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]

# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)

# Realizamos las densidades
dens(df)
```

> Respuesta Aqui


&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>
</p>

<p style="text-align: center;">
    <a href="https://discord.gg/XCbQvGs3Uf"><i class="fab fa-discord" style='font-size:30px'></i></a>
</p>

&nbsp;